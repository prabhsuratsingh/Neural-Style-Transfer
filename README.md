# Neural Style Transfer (NST) â€” PyTorch (VGG19)

This repository implements **Neural Style Transfer** using a pretrained **VGG-19** network in PyTorch.
The project generates a stylized image (or GIF) by combining the **content** of one image with the **style** of another using feature correlations (Gram matrices).

The model was developed and tested on an **NVIDIA GTX 1650 (4GB VRAM)**.

---

## Features

* VGG-19 feature extractor with **AvgPooling** (instead of MaxPooling)
* Content & style loss using **Gram matrices**
* Optimization via **L-BFGS**
* Optional **random noise** or **content image** initialization
* Periodic frame capture â†’ **animated GIF**
* CUDA support with automatic CPU fallback

---

## Model Architecture

* Backbone: **VGG-19 (ImageNet pretrained)**
* Feature layers used:

### Content Layer

```
conv4_2
```

### Style Layers

```
conv1_1
conv2_1
conv3_1
conv4_1
conv5_1
```

MaxPooling layers are replaced with **AvgPooling** to improve gradient smoothness and visual quality.

---

## Hardware & Performance

| Component  | Value           |
| ---------- | --------------- |
| GPU        | NVIDIA GTX 1650 |
| VRAM       | 4 GB            |
| Image Size | â‰¤ 512 px        |
| Iterations | 300             |
| Optimizer  | L-BFGS          |

> The project is optimized to fit comfortably within **4GB VRAM**.

---

## ðŸŽ¨ Neural Style Transfer Result

### Content Image
![Content Image](content-1.jpg)

### Style Image
![Style Image](style.jpg)

### Stylized Output (Optimization Progress)
![Neural Style Transfer GIF](style_transfer-2.gif)


---

## Requirements

```bash
pip install torch torchvision pillow
```

Tested with:

* Python â‰¥ 3.9
* PyTorch â‰¥ 2.0
* Torchvision â‰¥ 0.15

---

## Project Structure

```
.
â”œâ”€â”€ nst/
â”‚   â”œâ”€â”€ VGG.py              # VGG feature extractor
â”‚   â”œâ”€â”€ gram_matrix.py      # Gram matrix computation
â”‚   â””â”€â”€ live_viewer.py      # Tensor â†’ PIL conversion
â”‚
â”œâ”€â”€ content-1.jpg
â”œâ”€â”€ style.jpg
â”œâ”€â”€ style_transfer.py
â””â”€â”€ README.md
```

---

## Usage

### 1. Prepare Images

Place your images in the project root:

```text
content-1.jpg   # Content image
style.jpg       # Style reference
```

### 2. Run Style Transfer

```bash
python -m nst.main
```

### 3. Output

* Final result saved as:

```text
style_transfer-2.gif
```

Each frame represents optimization progress.

---

## Key Hyperparameters

```python
alpha = 1        # Content weight
beta  = 1e4     # Style weight
num_steps = 300
CAPTURE_EVERY = 5
```

### Initialization Options

```python
# Content initialization (more stable)
generated = content.clone().requires_grad_(True)

# Noise initialization (more artistic)
generated = torch.randn_like(content).requires_grad_(True)
```

---

## Loss Functions

### Content Loss

Mean-squared error between generated and content features:

L_content = â€–F_gen^(conv4_2) âˆ’ F_content^(conv4_2)â€–Â²

---

### Style Loss

Gram matrix MSE across style layers:

L_style = Î£_l â€–G_gen^l âˆ’ G_style^lâ€–Â²

---

### Total Loss

L = Î± Â· L_content + Î² Â· L_style


---

## Normalization

Images are normalized using ImageNet statistics:

```python
mean = [0.485, 0.456, 0.406]
std  = [0.229, 0.224, 0.225]
```

De-normalization is applied before saving frames.

---

## Notes

* `model.eval()` and `requires_grad=False` ensure the VGG network is **frozen**
* `LBFGS` requires a closure function (handled correctly)
* Clamping is optional and commented out to preserve texture richness

---

## Known Limitations

* High-resolution images (>512px) may exceed GTX 1650 VRAM
* L-BFGS is memory-intensive compared to Adam
* No batch processing (single image NST)

---

## References

* Gatys et al., *A Neural Algorithm of Artistic Style*
* PyTorch VGG-19 pretrained on ImageNet

---

## Author
Prabhsurat Singh

Developed as a **from-scratch PyTorch NST implementation**, optimized for **consumer GPUs**.
